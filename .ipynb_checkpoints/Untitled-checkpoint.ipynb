{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebbffa9-8e03-4060-b3cd-c0a0ceb8b258",
   "metadata": {},
   "source": [
    "### Previsão de Churn de Clientes com vários algoritmos \n",
    "XGBoost | ExtraTrees | SVC | CatBoost | DecisionTree\n",
    "\n",
    "- Este projeto destaca a necessidade de saber tratar bases de dados desbalanceadas (quando há pequena incidência de uma categoria dentro de um dataset (classe minoritária) em comparação com as demais categorias (classes majoritárias))\n",
    "- Como veremos, a grande maioria dos exemplos disponíveis no dataset representam casos em que não houve 'churn'.\n",
    "- Existem cuidados especiais ao se avaliar um algoritmo de Machine Learning quando se trata de datasets desbalanceados. Se desenvolvermos um modelo sem considerar essa desproporcionalidade nos dados, poderá levar a uma falsa percepção de que o modelo possuiu alta acurácia e que produz ótimos resultados.\n",
    "\n",
    "Os dados para análise estão disponíveis no Kaggle: \n",
    "- [IT Customer Chrun (Goal : Imbalanced Dataset)](https://www.kaggle.com/datasets/soheiltehranipour/it-customer-churn/data)\n",
    "\n",
    "### Sobre os dados:\n",
    "\n",
    "O Churn indica se um cliente desistiu/cancelou detereminado serviço. Em negócios que cobram mensalmente por um serviço, o churn é um problema sério. Afinal, quando um cliente que paga uma mensalidade resolve cancelar, todo o faturamento da empresa é comprometido a longo prazo, não só no mês atual.\n",
    "\n",
    "Prever o 'Churn' de clientes implica saber quais clientes provavelmente sairão ou cancelarão a assinatura. Para várias empresas, geralmente uma previsão crítica pois frequentemente, como obter clientes custa mais do que manter os existentes.\n",
    "\n",
    "O dataset inclui informações sobre:\n",
    "\n",
    "- Clientes que saíram no último mês: a coluna é chamada 'Churn'\n",
    "- Serviços que cada cliente assinou: telefone, várias linhas, internet, segurança online, backup online, proteção de dispositivo, suporte técnico e streaming de TV e filmes\n",
    "- Informações da conta do cliente: há quanto tempo ele é cliente, contrato, método de pagamento, faturamento sem papel, cobranças mensais e cobranças totais\n",
    "- Informações demográficas sobre os clientes: sexo, faixa etária e se eles têm parceiros e dependentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c158801-58bb-4db7-9ea8-5484437946d7",
   "metadata": {},
   "source": [
    "- [1. Importar e limpar os dados](#1-importar-e-limpar-os-dados)\n",
    "- [2. Visualizando os dados](#2-visualizando-os-dados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b47e5-9d37-41de-9329-8b246fe14cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliotecas que serão utilizadas no projeto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix, f1_score, classification_report, roc_curve, auc\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import KFold, GridSearchCV, KFold, cross_val_score, train_test_split\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f60ef3-7949-4384-b634-89c43b8f2ba1",
   "metadata": {},
   "source": [
    "### 1. Importar e limpar os dados <a id=\"1-importar-e-limpar-os-dados\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00bc2ec-d8f1-42ff-9837-23be73e7ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar o dataset\n",
    "df = pd.read_csv('IT_customer_churn.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7dfdd-0015-4262-8a99-13fdf45e1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizando os dados\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3138f73a-59ed-4c6b-99bb-769dd68265b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtendo informações de tipos de dados reconhecidos e se há valores nulos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae6e37f-6ae4-4a41-8b7e-eee7cebe17a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando os valores existentes pra cada coluna\n",
    "for coluna in df.columns:\n",
    "    print(f'{coluna} : {df[coluna].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b66f23-0007-458b-9a8f-c151186588de",
   "metadata": {},
   "source": [
    "**Não há valores nulos na base de dados, porém há alguns problemas identificados:**\n",
    "\n",
    "- **Coluna gender deve ser convertida para formato numérico. Uma possível solução é 'Male' = 1 e 'Female' = 0**\n",
    "- **Colunas do tipo booleano: Transformar os valores 'Yes' para 1 e 'No' para 0 e então converter para tipo numérico.**\n",
    "- **Coluna TotalCharges é o valor total pago pelo cliente até então. Esta coluna foi reconhecida como objeto e deve ser convertida pro formato de número.**\n",
    "- **As colunas InternetService, Contract e PaymentMethod possuem valores categóricos. Será realizado o encoding para estas colunas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e050e846-4a10-42bf-b8a5-198a859528bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter a coluna TotalCharges para numérico\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1ca07b-4ab1-49ac-a27f-c8339df3fc90",
   "metadata": {},
   "source": [
    "- **Após transformar a coluna TotalCharges para numérico, alguns valores estavam preenchidos como espaço em branco (' '), portanto serão excluídos do modelo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f0ba5e-355d-4b05-8ff6-5a766829b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4d247b-0838-4866-88fc-09bf76c0afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b2712-0c6a-4aff-9310-34473657647e",
   "metadata": {},
   "source": [
    "### 2. Visualizando os dados <a id=\"2-visualizando-os-dados\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbcdb6-0d1d-4deb-acc1-70d1e6ce4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a distribuição dos valores na feature Churn\n",
    "\n",
    "# Contagem dos valores de Churn\n",
    "data = df['Churn'].value_counts()\n",
    "\n",
    "# Criação do gráfico de pizza com rótulos personalizados e uma legenda\n",
    "sns.set_theme(style='dark', palette='colorblind', context='notebook')\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(x=data, labels=data.values, autopct='%1.1f%%', explode=(0, 0.1), shadow=True, startangle=90)\n",
    "ax.legend(data.index)\n",
    "plt.title(\"Distribuição de Churn\")\n",
    "\n",
    "# Exibição do gráfico\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970ef138-7c78-466c-9db9-3e3c359664a4",
   "metadata": {},
   "source": [
    "- **Com o gráfico acima, fica evidente o desbalancemaneto na ocorrência de Churn para este dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779cd4e4-0aeb-47b5-8db4-5fe73e19b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando a presença de outliers nas colunas tenure, MonthlyCharges e TotalCharges\n",
    "colunas_numericas = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "\n",
    "plt.style.use('seaborn-v0_8-colorblind')\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16,8), tight_layout=True)\n",
    "for i in range(len(colunas_numericas)):\n",
    "    sns.boxplot(y=colunas_numericas[i], data=df, ax=axs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33933858-7cab-44b2-93dc-f3d4021af2ad",
   "metadata": {},
   "source": [
    "- **Observa-se portanto que não há valores muito discrepantes para essas 3 features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c1be5-b82b-4993-ba13-f4d0318692bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o Churn com relação ao número de serviços contratados \n",
    "\n",
    "# Criando nova coluna com a quantidade de serviços adquiridos por cliente\n",
    "df['internet'] = df['InternetService'].apply(lambda x: 'No' if x == 'No' else 'Yes')\n",
    "\n",
    "df['num_services'] = (df[['PhoneService', 'OnlineSecurity',\n",
    "                          'OnlineBackup', 'DeviceProtection',\n",
    "                          'TechSupport', 'StreamingTV',\n",
    "                          'StreamingMovies', 'internet', 'MultipleLines']] == 'Yes').sum(axis=1)\n",
    "\n",
    "sns.set_theme(style='dark', palette='colorblind', context='notebook')\n",
    "\n",
    "sns.histplot(x='num_services', data=df, hue='Churn', multiple='dodge')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceedcb8-23a2-4cce-a49e-7c9abb5f01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a percentagem de Churn em relação ao número de serviços contratados \n",
    "pd.crosstab(df[\"num_services\"], df[\"Churn\"], normalize=\"index\", margins=True, margins_name=\"Total\").mul(100).round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f1e44-5792-41e8-ba20-746f588b6a22",
   "metadata": {},
   "source": [
    "- **Parece não haver correlação direta entre o número de serviços contratados e churn, mesmo assim iremos manter essa coluna no modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182caad2-81db-4ba8-859a-e2e491daf248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a distribuição dos valores nas colunas numéricas\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(14,6), tight_layout=True)\n",
    "for i in range(len(colunas_numericas)):\n",
    "    sns.histplot(x=colunas_numericas[i], data=df, multiple='dodge', ax=axs[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0b8d73-2951-4345-8bdf-bcff241d0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a contagem de churn para cada variável numérica\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(14,6), tight_layout=True)\n",
    "\n",
    "for i in range(len(colunas_numericas)):\n",
    "    sns.histplot(x=colunas_numericas[i], data=df, hue='Churn', multiple='dodge', ax=axs[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6934c3-ad2e-4eb7-8b52-32ce074bd31f",
   "metadata": {},
   "source": [
    "- **É possível observar que o Churn tende a diminuir conforme os valores de 'tenure' (que indicam o tempo em meses do cliente na empresa) diminui**\n",
    "- **O mesmo ocorre com os valores de TotalCharges**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0636404-ddf0-4c4d-95de-094850daa28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando o Churn por tipo de contrato\n",
    "sns.histplot(x='Contract', data=df, hue='Churn', multiple='stack', shrink=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e3d379-6149-4492-851e-3ccf564aface",
   "metadata": {},
   "source": [
    "- **O Churn tende a diminuir conforme aumenta a duração do contrato. Isso explica o motivo de algumas empresas fornecerem descontos e atrativos para favorecer os contratos anuais**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a941b36-66b7-411a-b330-91a0370cacfd",
   "metadata": {},
   "source": [
    "### 3. Preparando os dados para o modelo de previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d09d54-b539-441d-a809-83213d699479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter a coluna gender para numérico: 'Male' = 1 e 'Female' = 0\n",
    "df['gender'] = df['gender'].apply(lambda x: 1 if x == 'Male' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24a88a-ba13-4429-a56d-815227b2a77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_bool = ['Partner', 'Dependents', 'PhoneService', 'MultipleLines', 'OnlineSecurity', \n",
    "                'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n",
    "               'StreamingMovies', 'PaperlessBilling', 'Churn']\n",
    "\n",
    "# converter todos os valores 'Yes' para 1 e os outros possíveis ('No', 'No internet service', 'No phone service') para 0 \n",
    "for coluna in colunas_bool:\n",
    "    df[coluna] = df[coluna].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21df089c-6c43-4129-b2fd-c5a535aa4662",
   "metadata": {},
   "source": [
    "#### 3.1. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa5eb0-8089-4ec7-8044-70c0f71d6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se o cliente está comprometido com os serviços da empresa, ou seja, se o tipo de contrato for diferente de Mês-a-Mês, o valor retornado será 1 (Yes)\n",
    "df['comprometido'] = np.where(df['Contract'] != 'Month-to-month', 1.0, 0.0)\n",
    "\n",
    "# Verifica se o cliente possui algum tipo de serviço de proteção contratado e retorna 1 caso possua pelo menos um.\n",
    "df['protecao'] = np.where((df['OnlineBackup'] != 0) | (df['DeviceProtection'] != 0) | (df['TechSupport'] != 0), 1.0, 0.0)\n",
    "\n",
    "# Cliente Senior com Dependentes\n",
    "df['senior_com_dependentes'] = np.where((df['SeniorCitizen'] == 1) & (df['Dependents'] == 1), 1.0, 0.0)\n",
    "\n",
    "# Cliente jovem e comprometido\n",
    "df['jovem_comprometido'] = np.where((df['SeniorCitizen'] == 0) & (df['Contract'] != 'Month-to-month'), 1.0, 0.0)\n",
    "\n",
    "# Cliente com todos os serviços de proteção\n",
    "df['todo_protegido'] = np.where((df['OnlineSecurity'] != 0) & (df['OnlineBackup'] != 0) & (df['DeviceProtection'] != 0), 1, 0)\n",
    "\n",
    "# Cliente com Alta Fatura Mensal e Longo Tempo de Permanência \n",
    "df['alta_fatura_longo_tempo'] = np.where((df['MonthlyCharges'] > df['MonthlyCharges'].median()) & (df['tenure'] > df['tenure'].median()), 1.0, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c782543d-85de-41f7-bc7e-ef4a331d8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtendo novamente os tipos de dados\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47082164-a129-460d-b49a-add52751543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo o encoding para as colunas InternetService, Contract, PaymentMethod, num_services e internetd\n",
    "colunas_categorias=['InternetService', 'Contract', 'PaymentMethod', 'num_services', 'internet']\n",
    "df_cod = pd.get_dummies(data=df, columns=colunas_categorias, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28519b5-7ce9-4367-8644-9e11123eed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificando novamente os valores existentes pra cada coluna\n",
    "for coluna in df_cod.columns:\n",
    "    print(f'{coluna} : {df_cod[coluna].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a70c2-4273-4041-b691-211a71e74396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c685ec5-09db-4e1e-a03c-1eaa779d80a2",
   "metadata": {},
   "source": [
    "- **Removendo colunas com alta correlação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a7749-2c1b-44a8-8d46-63be181b50ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limite para remoção de variáveis altamente correlacionadas\n",
    "limite_corr = 0.90\n",
    "\n",
    "# Matriz de correlação de valor absoluto\n",
    "corr_matrix = df_cod.corr().abs()\n",
    "\n",
    "# Obtendo o triângulo superior de correlações\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Selecionando colunas com correlações acima do limite\n",
    "para_remover = [column for column in upper.columns if any(upper[column] > limite_corr)]\n",
    "\n",
    "print('Há %d colunas a remover' % (len(para_remover)))\n",
    "print(list(para_remover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd894bcd-d09d-4b9a-8705-1b829bac0c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cod = df_cod.drop(columns = para_remover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6facd7-97f4-4bb5-8ed6-62cb61f3e383",
   "metadata": {},
   "source": [
    "#### 3.2. Normalizando os valores\n",
    "**A normalização dos dados é crucial em muitos modelos de Machine Learning. Isso é feito para garantir que todas as variáveis estejam na mesma escala, o que ajuda a:**\n",
    "- **Facilita a convergência mais rápida dos modelos durante o treinamento.**\n",
    "- **Melhora a precisão das previsões dos modelos.**\n",
    "- **Permite que os modelos aprendam pesos mais apropriados para cada característica.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68444b70-e57d-4ebb-b438-f4ff8d8bb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando o normalizador\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# ajustando o conjunto de dados no normalizador\n",
    "normal = scaler.fit_transform(df_cod)\n",
    "# criando o dataframe a partir dos dados normalizados\n",
    "normal_df = pd.DataFrame(normal, columns= df_cod.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6163450-3af8-4ad4-8e84-4476b2b5a7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando X e y a partir dos dados normalizados\n",
    "X = normal_df.drop(columns='Churn', axis=1)\n",
    "y = normal_df['Churn']\n",
    "\n",
    "# criando X, y de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11, stratify=y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222bf6cd-46d8-49b0-a680-23949f965f7f",
   "metadata": {},
   "source": [
    "### 4. Criando os diferentes modelos de classificação\n",
    "- Escolha dos modelos a serem testados\n",
    "  1. XGBoost\n",
    "  2. ExtraTrees\n",
    "  3. SVC\n",
    "  4. CatBoost\n",
    "  5. DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e40636-0eae-4b42-89b1-b7e5cfb4191b",
   "metadata": {},
   "source": [
    "#### 4.1. Antes de criar os modelos, vamos primeiro encontrar os melhores hiperparâmetros para cada um deles utilizando o GridsearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbea393-6374-4e71-962e-0a6caa3bf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelos e seus respectivos parâmetros\n",
    "modelos = {\n",
    "    'XGB': XGBClassifier(),\n",
    "    'ExtraTrees': ExtraTreesClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'Ridge': RidgeClassifier(),\n",
    "    'DecisionTree': DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "hiperparametros = {\n",
    "    'XGB': {'n_estimators': [100, 200, 500, 1000],\n",
    "            'learning_rate': [0.01, 0.001, 1.0],\n",
    "            'subsample': [0.75],\n",
    "            'colsample_bytree': [1],\n",
    "            'random_state': [11],\n",
    "            'max_depth': [1, 3, 5]},\n",
    "\n",
    "    'ExtraTrees': {'n_estimators': [100, 200, 500, 1000],\n",
    "                   'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "                   'random_state': [11],\n",
    "                   'max_depth': [1, 3, 5]},\n",
    "\n",
    "    'SVC': {'tol': [0.01, 0.001, 0.0001],\n",
    "            'random_state': [43],\n",
    "            'C': [1.0, 3.0, 5.0]},\n",
    "\n",
    "    'Ridge': {'alpha': [1.0, 2.0, 3.0],\n",
    "             'tol': [0.01, 0.001, 0.0001],\n",
    "             'random_state': [43]},\n",
    "    \n",
    "    'DecisionTree': {'splitter': ['best', 'random'],\n",
    "                     'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "                     'min_samples_leaf': [1, 2, 3],\n",
    "                     'min_samples_split': [2, 3, 4, 5],\n",
    "                     'random_state': [11],\n",
    "                     'max_depth': [1, 3, 5]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21d25f0-d6af-4fe1-9ccb-c7ded864b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para encontrar os melhores parâmetros\n",
    "def encontrar_melhores_hiperparametros(modelos, hiperparametros):\n",
    "    melhores_hiperparametros = {}\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=11)\n",
    "    \n",
    "    for nome_modelo, modelo in modelos.items():\n",
    "        print(f'Ajustando parâmetros para {nome_modelo}...')\n",
    "        \n",
    "        grid_search = GridSearchCV(estimator=modelo, param_grid=hiperparametros[nome_modelo], cv=kf, refit=True, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Armazenar os melhores parâmetros e as métricas\n",
    "        melhores_hiperparametros[nome_modelo] = grid_search.best_params_\n",
    "    \n",
    "    return melhores_hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d233b-483e-4b36-a4dc-07e546a833cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encontrar os melhores parâmetros\n",
    "melhores_hiperparametros = encontrar_melhores_hiperparametros(modelos, hiperparametros)\n",
    "\n",
    "# Imprimindo os melhores parâmetros\n",
    "for modelo, parametros in melhores_hiperparametros.items():\n",
    "    print(modelo, ':', parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8525e9d-a194-40db-b1ec-11228a50475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_otimizados = {\n",
    "    'XGB': XGBClassifier(**melhores_hiperparametros['XGB']),\n",
    "    'ExtraTrees': ExtraTreesClassifier(**melhores_hiperparametros['ExtraTrees']),\n",
    "    'SVC': SVC(**melhores_hiperparametros['SVC']),\n",
    "    'Ridge': RidgeClassifier(**melhores_hiperparametros['Ridge']),\n",
    "    'DecisionTree': DecisionTreeClassifier(**melhores_hiperparametros['DecisionTree'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0748b-f478-4da2-a255-7f587c51092a",
   "metadata": {},
   "source": [
    "- **Avaliando os modelos...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31a52c-87b0-48d8-93d6-5191907a88d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando apenas F1-Score como métrica de avaliação\n",
    "scoring = 'f1'\n",
    "n_folds = 10\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=11)\n",
    "\n",
    "# Dicionário para armazenar os resultados\n",
    "res = {}\n",
    "\n",
    "for nome_modelo, modelo in modelos_otimizados.items():\n",
    "    cv_results = cross_val_score(modelo, X_train, y_train, cv=kfold, scoring=scoring, n_jobs=-1)    \n",
    "    res[nome_modelo] = cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a9d937-083e-4c4a-b7b0-2d95774b92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir todos os resultados\n",
    "for nome_modelo, resultado in res.items():\n",
    "    print(\"%s: %f (+/- %f)\" % (nome_modelo, resultado.mean(), resultado.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e6e22a-46e9-412b-b91b-f26b54bc08e4",
   "metadata": {},
   "source": [
    "- F1-Score: É a média harmônica da precisão e do recall, fornecendo uma única métrica de desempenho que leva em conta ambos. É particularmente útil quando se tem um desbalanceamento de classes, já que captura tanto falsos positivos quanto falsos negativos.\n",
    "\n",
    "**Considerando que o conjunto de dados está desbalanceado, o F1-Score se mostra uma métrica mais relevante para avaliar o desempenho dos modelos. Todos os modelos obtiveram valores de F1-Score bem próximos variando entre 0,5 e 0,6. Diante disso, é recomendável realizar manipulações no conjunto de dados para aprimorar o desempenho dos modelos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab083ee1-d881-46cc-b6ad-24ad3b8790a8",
   "metadata": {},
   "source": [
    "### 5. Balanceando o dataset com uso do SMOTE\n",
    "\n",
    "Em datasets onde há grande disparidade no número das classes disponíveis, muitas das vezes, pode ser necessário rebalancear os dados, aumentando o número de exemplos para a classe minoritária ou removendo exemplos da classe majoritária\n",
    "\n",
    "Para realizar este processo, existem diversas estratégias. Uma delas é usar o SMOTE (Synthetic Minority Oversampling Technique), um dos métodos mais utilizados para resolver problemas de desbalanceamento. O SMOTE consiste em identificar as amostras da classe minoritária e, para cada exemplo dessa classe, o algoritmo seleciona alguns de seus vizinhos e realiza a interpolação, gerando novos exemplos sintéticos. Isso aumenta o número de amostras da classe minoritária, balanceando o conjunto de dados\n",
    "\n",
    "**Vale destacar que este processo pode ser feito apenas no conjunto de treinamento. O conjunto de teste deve refletir a realidade e portanto não deve sofrer alterações na distribuição de churn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68006d1-d179-436a-8997-97a9b6dfe1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando a biblioteca para balancear\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Balanceando o somente os valores de X e y de treino do dataset\n",
    "smote = SMOTE(sampling_strategy='minority', random_state=11)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee86a14e-9a02-4cee-9644-46fb4de28a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando apenas F1-Score como métrica de avaliação\n",
    "scoring = 'f1'\n",
    "n_folds = 10\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=11)\n",
    "\n",
    "# Dicionário para armazenar os resultados\n",
    "res_smote = {}\n",
    "\n",
    "for nome_modelo, modelo in modelos_otimizados.items():\n",
    "    cv_results = cross_val_score(modelo, X_train_smote, y_train_smote, cv=kfold, scoring=scoring, n_jobs=-1)    \n",
    "    res_smote[nome_modelo] = cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710c945-a44f-45a3-87f8-d14e9ccab279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold do scikit-learn\n",
    "kfold = KFold(n_splits=10)\n",
    "\n",
    "# lista de acuracias de cada split\n",
    "res_smote = {}\n",
    "\n",
    "# iterando sobre os splits\n",
    "for nome_modelo, modelo in modelos_otimizados.items():\n",
    "    scores_split = []\n",
    "    for idx, (idx_treino, idx_validacao) in enumerate(kfold.split(X_train)):\n",
    "        X_split_treino = X_train.iloc[idx_treino,]\n",
    "        y_split_treino = y_train.iloc[idx_treino,]\n",
    "    \n",
    "        # oversampling, só no split de treino!!\n",
    "        sm = SMOTE(random_state=11)\n",
    "        X_split_treino, y_split_treino = sm.fit_resample(X_split_treino, y_split_treino)\n",
    "        \n",
    "        # Com os dados balenceados SÓ NO TREINO, vamos treinar o nosso modelo\n",
    "        modelo.fit(X_split_treino, y_split_treino.values.flatten())\n",
    "    \n",
    "        X_split_validacao = X_train.iloc[idx_validacao,]\n",
    "        y_split_validacao = y_train.iloc[idx_validacao,]\n",
    "        \n",
    "        # Validação SEM oversampling\n",
    "        # Amostra do mundo real, ou seja, com dados DESBALANCEADOS\n",
    "        predicoes_validacao = modelo.predict(X_split_validacao)\n",
    "        \n",
    "        f1_split = f1_score(y_split_validacao, predicoes_validacao)\n",
    "        \n",
    "        scores_split.append(f1_split)\n",
    "        \n",
    "    res_smote[nome_modelo] = np.array(scores_split)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a879a-c08c-4551-910e-0dd4f5a2be96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir todos os resultados\n",
    "for nome_modelo, resultado in res_smote.items():\n",
    "    print(\"%s: %f (+/- %f)\" % (nome_modelo, resultado.mean(), resultado.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a1bd7-fdb7-400f-bd7c-481c163cc932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevendo para os novos valores X_test e comparando com y_test\n",
    "for nome_modelo, modelo in modelos_otimizados.items():\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Usando apenas F1-Score como métrica de avaliação\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'{nome_modelo}: {score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd15a2-a266-43f6-bb5c-0a057d540983",
   "metadata": {},
   "source": [
    "- **Os valores de F1-score apresentaram uma pequena melhora quando o modelo foi aplicado aos dados de treino. No entanto, ao realizar previsões utilizando os dados de teste, observou-se uma queda nos valores de F1-score, indicando uma possível discrepância entre o desempenho do modelo em ambientes de treino e teste.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9baaf6-84d5-4c5f-bdc6-d0d13c7c603d",
   "metadata": {},
   "source": [
    "### 6. Balanceando o dataset com uso de class_weight\n",
    "\n",
    "Em problemas de classificação com dados desbalanceados, aplicar class_weight pode ser uma boa alternativa. Essa técnica ajusta o processo de treinamento, permitindo que o modelo dê mais atenção às classes minoritárias. Ao atribuir um peso maior às instâncias dessas classes, o desbalanceamento dos dados é compensado, resultando em uma melhoria significativa na capacidade do modelo de detectar corretamente a classe minoritária."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d09550-dc25-4e64-856b-091ce1b6ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando X, y de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894d3cd-30ec-4721-80db-c96bcd7433ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando apenas F1-Score como métrica de avaliação\n",
    "scoring = 'f1'\n",
    "n_folds = 10\n",
    "kfold = KFold(n_splits=n_folds, shuffle=True, random_state=11)\n",
    "\n",
    "# Dicionário para armazenar os resultados\n",
    "res_pesos = {}\n",
    "\n",
    "for nome_modelo, modelo in modelos_otimizados.items():\n",
    "    if nome_modelo == 'XGB':\n",
    "        # Adicionando class_weight como balanceado para o caso do classificador XGB\n",
    "        modelo.set_params(scale_pos_weight=sum(y_train == 0)/sum(y_train == 1))\n",
    "    else:\n",
    "        # Adicionando class_weight como balanceado para os demais casos\n",
    "        modelo.set_params(class_weight='balanced')\n",
    "        \n",
    "    cv_results = cross_val_score(modelo, X_train, y_train, cv=kfold, scoring=scoring, n_jobs=-1)    \n",
    "\n",
    "    res_pesos[nome_modelo] = cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041bef23-e934-40d1-a8d6-1fa12828a6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir todos os resultados\n",
    "for nome_modelo, resultado in res_pesos.items():\n",
    "    print(\"%s: %f (+/- %f)\" % (nome_modelo, resultado.mean(), resultado.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca06cfdd-9940-4439-8617-3ebf41500f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prevendo para os novos valores X_test e comparando com y_test\n",
    "for nome_modelo, modelo in modelos_otimizados.items():\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Usando apenas F1-Score como métrica de avaliação\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'{nome_modelo}: {score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a39a042-01c8-413f-b77b-78b3264f1ab4",
   "metadata": {},
   "source": [
    "- **Ao aplicar pesos para as classes do dataset, foi observada uma melhora consistente em todos os modelos. Destaca-se o modelo ExtraTrees, que apresentou um aumento de 0.1 no F1-Score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656dfcb-c2a9-491c-be83-6c975c2ab7fc",
   "metadata": {},
   "source": [
    "### 7. Plotando matriz de confusão e curva ROC para análise mais aprofundada (apenas para o melhor modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b9bf0-5e03-49d6-a726-8b99d078a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o melhor modelo\n",
    "modelo = XGBClassifier(**melhores_hiperparametros['XGB'], scale_pos_weight=sum(y_train == 0)/sum(y_train == 1))\n",
    "\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('predict No Churn', 'predict Churn'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual No Churn', 'Actual Churn'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='gray')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81203830-d661-4116-99bf-01b220367192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obter as probabilidades de predição\n",
    "y_pred_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular as taxas de verdadeiros positivos e falsos positivos\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Calcular a AUC (Área sob a Curva) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotar o gráfico ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'Curva ROC (área = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87de319-1581-415b-8883-5f2da21bce37",
   "metadata": {},
   "source": [
    "### Interpretação dos Resultados\n",
    "\n",
    "- **Com base no gráfico acima, observa-se que a área sob a curva ROC é de 0.84, o que indica uma performance bastante positiva do modelo de classificação. Este resultado é especialmente relevante no contexto do projeto, uma vez que prever o Churn de um cliente pode trazer benefícios significativos para a empresa, como melhorar a retenção de clientes e aumentar a satisfação. Embora a previsão de churn possa não ser tão crítica quanto a prevenção de fraudes em cartões de crédito ou o diagnóstico e prevenção de doenças médicas, ela desempenha um papel crucial na estratégia de negócios e no sucesso a longo prazo da organização.**\n",
    "\n",
    "\n",
    "- **Com relação à matriz de confusão, observa-se que o Recall para Churn, uma métrica crucial no contexto deste problema de negócio, atingiu um bom valor de 0.789. Isso significa que 295 dos 374 (78.9%) dos casos de churn foram corretamente identificados como tal.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675067f-fe65-4a53-a81f-901ed766a819",
   "metadata": {},
   "source": [
    "### 8. Tentando melhorar o modelo removendo features menos importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ead09d-351e-400a-bb8c-959f1deaa691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o melhor modelo\n",
    "modelo = XGBClassifier(**melhores_hiperparametros['XGB'], scale_pos_weight=sum(y_train == 0)/sum(y_train == 1)) \n",
    "\n",
    "# Treinando o modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Extraindo os coeficientes\n",
    "coeficientes = modelo.feature_importances_\n",
    "\n",
    "# Criando um DataFrame para uma melhor visualização\n",
    "features_df = pd.DataFrame({'Feature': X_train.columns, 'Coefficient': coeficientes})\n",
    "features_df['Importance'] = np.abs(features_df['Coefficient'])\n",
    "features_df = features_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotando o gráfico de barras horizontal\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(features_df['Feature'], features_df['Importance'])\n",
    "plt.xlabel('Importância (Valor Absoluto do Coeficiente)')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Importância das Features (RidgeClassifier)')\n",
    "plt.gca().invert_yaxis()  # Inverter a ordem das features\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bff9e2-c682-4840-83e2-48d4e3b0aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as features com importância menor que o valor limite\n",
    "limite_importancia = 0.01\n",
    "features_menor_importancia = features_df[features_df['Importance'] < limite_importancia]\n",
    "\n",
    "# Lista de colunas a serem removidas\n",
    "colunas_para_remover = features_menor_importancia['Feature'].tolist()\n",
    "colunas_para_remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f714db4-1142-4253-b018-831bb41f5d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover as colunas do DataFrame original\n",
    "df_modificado = normal_df.drop(columns=colunas_para_remover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa0acc5-108e-4905-8847-9bf4ace786c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando X e y a partir dos dados normalizados\n",
    "X = df_modificado.drop(columns='Churn', axis=1)\n",
    "y = df_modificado['Churn']\n",
    "\n",
    "# criando X, y de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11, stratify=y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965ba1f-d877-4573-8097-739e3829f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nome_modelo, modelo in modelos_otimizados.items():\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    \n",
    "    # Usando apenas F1-Score como métrica de avaliação\n",
    "    score = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'{nome_modelo}: {score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02bafc4-f850-4f74-9183-05fd3ad22327",
   "metadata": {},
   "source": [
    "- **Pequena melhora no modelo RidgeClassifier (0.63080 contra 0.62620)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4319afac-0392-4ef4-94eb-55ffefeb24fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando o modelo\n",
    "modelo = RidgeClassifier(**melhores_hiperparametros['Ridge'], class_weight='balanced')\n",
    "\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# Matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred) \n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.imshow(cm)\n",
    "ax.grid(False)\n",
    "ax.xaxis.set(ticks=(0, 1), ticklabels=('predict No Churn', 'predict Churn'))\n",
    "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual No Churn', 'Actual Churn'))\n",
    "ax.set_ylim(1.5, -0.5)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='gray')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e3345b-7ec9-45dd-9ced-3703c1d5f22f",
   "metadata": {},
   "source": [
    "- **Após remover algumas features menos importantes e simplificar o modelo, percebeu-se uma pequena melhora no Recall, saindo de 0.789 para 0.799 (299/374).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001ef96-febc-4503-8d5e-1b547b3f5f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrando o modelo para obter predições probabilísticas\n",
    "calibrated_model = CalibratedClassifierCV(modelo, method='sigmoid')\n",
    "calibrated_model.fit(X_train, y_train)\n",
    "\n",
    "# Obter as probabilidades de predição\n",
    "y_pred_proba = calibrated_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calcular as taxas de verdadeiros positivos e falsos positivos\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Calcular a AUC (Área sob a Curva) \n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plotar o gráfico ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'Curva ROC (área = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c69d45-62d6-4156-81a8-af2e6bf5de75",
   "metadata": {},
   "source": [
    "- **Já para o caso da Curva ROC e sua área AUC, não houve impacto.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
